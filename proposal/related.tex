\section{Related Work}

On the surface, it appears that there has not been much academic interest in combining computer science and venture capital. This is because most of the work done in leveraging data and machine learning to identify new opportunities and make superior investment decisions happens at venture firms where proprietary knowledge is a business advantage, and there is no incentive to share information. We therefore see very few papers published in the space, despite organizations like SignalFire~\cite{signalfire}, building what amounts to ``a  mini proprietary Google''~\cite{techrunch-signalfire} to aid in investment decisions and strategic portfolio support, and Correlation Ventures, which has built ``one of the worldâ€™s most complete databases of venture capital financings''~\cite{correlation-about} for use in their predictive models.

There has also been significant work done in financial and economic academic explorations of venture capital that we can leverage. For example, we plan on borrowing several learnings from \cite{2017arXiv170604229H}, including the list of sector names to use as binary features for a company and the calculated features for both investors and founders.

Another example are the various economic models summarized in \cite{venture-survey}, which include the problems of picking startups, matching founders to investors, and the interactions between venture firms and companies. While none of these consider the practical ways we can improve these processes through computer science, they provide a background for the challenges at hand, and present mathematical abstractions which may be useful in our models.

Finally, there have been several publications describing the difficulties accompanying the sparse, noisy data found in venture. Thomas Stone's thesis on Computational Analytics for Venture Finance~\cite{stone2014computational} delves into many of the problems with the publicly-available datasets. He proposes solutions to issues such as poor class labels, with supervised learning models that define a new, more granular schema, using existing schemas as input.

For the work remaining on the proposed tools, there has also been recent and relevant literature published.

\subsection*{FounderRank}

We will be building on two bodies of work for the further exploration and implementation of FounderRank: document classification techniques for filtering and categorizing nodes in our graph, and node ranking algorithms, for surfacing the most relevant nodes in our final graphs.

Much of the work to be done on FounderRank requires shaping our web page crawl graphs to match the structure we expect. Much literature has been produced in the domain of text classification.

The first falls into the camp of extracting features from documents, and then feeding these feature vectors into standard models, such as Support Vector Machines (SVM) or a Naive Bayes classifier. The common feature vector is a bag-of-words model, and adding complex linguistic features to this model does not provide much benefit~\cite{Moschitti2004}. The time-tested term frequency-inverse document frequency (tf-idf) statistic is also often used in place of word counts~\cite{Salton:1986:IMI:576628}. Extrapolating on the word2vec methodology~\cite{DBLP:journals/corr/abs-1301-3781} of learning an embedding of word vectors, a team at Google has also proposed the ``Paragraph Vector''~\cite{DBLP:journals/corr/LeM14}, a distributed fixed-length feature representation of documents that automatically captures word ordering and semantics with recurrent neural networks (RNNs).

In the second camp are solutions that attempt to categorize documents in one shot, learning a classification directly from the text. These often employ convolutional neural nets (CNNs). One solution models documents in low-dimensional representations from hierarchical filters at the sentence and document level~\cite{DBLP:journals/corr/DenilDKBF14} (similar to Paragraph Vectors, but using CNNs to capture local context instead of the temporal context provided by RNNs). Another uses character-level convolution, treating the document as a series of raw signals and using convolutional filters to generate representative features~\cite{DBLP:journals/corr/ZhangZL15}. In their case, these representations are fed into fully-connected predictive layers of a neural net which can output distributions over categories.

When it comes to ranking nodes in a graph, there is a large body of literature to reference. The canonical starting point is of course PageRank~\cite{page1999pagerank}, which recursively estimates node importance by analyzing the importance of nodes which link to the node in question. HITS~\cite{kleinberg1999authoritative}, a simple algorithm which calculates authority and hub scores, is also commonly used. Several variations exist, included a Weighted Page Rank~\cite{xing2004weighted}. While these algorithms do a good job ranking nodes in a graph for search relevance, they don't necessarily capture desirable characteristics for interesting nodes in a venture context. It is unclear if there even exists a canonical ranking for nodes in a graph for venture, since desirable properties depend on the company.

Thus, we look at learned graph node ranking algorithms. Strategies such as the Graph Neural Network (GNN)~\cite{scarselli2009graph} help neural nets directly process graphs, which has lead to the development of systems which use GNNs to rank web pages~\cite{scarselli2005graph}. Crucially, this algorithm does not require explicitly determining which factors are important for ranking, and can be learned from a small number of training examples in the form of inequalities. Further work has then been done extending the idea of GNNs, with gating and other modern enhancements~\cite{DBLP:journals/corr/LiTBZ15}.

\subsection*{VCWiz}

The work of Stone at UCL is the best starting point for related previous work in the area of recommendation systems for venture capital. In \cite{Stone:2013:EST:2541167.2507882}, the authors explore the difficult task of building a top-N recommendation system for venture firms considering investments - the inverse of the problem we are trying to solve. While not the same problem, Stone et al. discovered the difficulty in building a recommendation system with hyper-sparse data sets such as the set of venture fundings in the US, which is roughly the same data set we will be using (albeit from different sources). Their insight of leveraging both content-based and collaborative filtering, combined via a linear ensemble method, will be the inspiration for our hybrid classifier.

Current literature in recommendation systems defines (at least) two broad categories of systems: content-based and collaborative filtering~\cite{Burke2002}. Content-based systems characterize users with features extracted from the items they have preferences for, then use these features to find other items with similar features. Collaborative filtering, on the other hand, characterizes users by the set of preferences they have for a canonical set of items (without knowledge of the actual items), and suggests new items by finding users with similar preferences, and returning the items that they prefer. These two systems take different information into account, and can be combined into hybrid models that capture both perspectives.

Combining the models helps us mitigate some of the adverse effects of using one or the other. For example, content-based systems struggle to recommend items which are not associated with existing user items, since there are no similar features. Collaborative systems fix this by pulling items from similar users, agnostic of the item itself, but suffer from other issues, such as degraded results when users each only review a few items.

While there are other recommendation models to explore, it's accepted that ``learning-based technologies work best for dedicated users who are willing to invest some time making their preferences known to the system''~\cite{Burke2002}, which reflects our situation.
